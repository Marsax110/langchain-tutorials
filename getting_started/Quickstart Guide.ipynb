{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed4da4d",
   "metadata": {},
   "source": [
    "## Quickstart Guide\n",
    "https://langchain.readthedocs.io/en/latest/getting_started/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a05530b1",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-26T14:19:05.076447Z",
     "start_time": "2023-12-26T14:19:05.067286Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b556fc2",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-26T14:19:05.308753Z",
     "start_time": "2023-12-26T14:19:05.304229Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c07fe20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:20:01.378755Z",
     "start_time": "2023-12-26T14:20:01.372384Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126a6a1",
   "metadata": {},
   "source": [
    "# Building A Language Model Application 构建一个语言模型应用\n",
    "### LLMS: Get predictions from a language model LLMS：从语言模型获取预测结果\n",
    "\n",
    "1. 从llms中选择一个语言模型\n",
    "2. 实例化一个语言模型，设定参数\n",
    "3. 定义一个输入文本变量\n",
    "4. 用语言模型预测输入文本变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bef95a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:20:46.796578Z",
     "start_time": "2023-12-26T14:20:46.790191Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3596e426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:20:47.876770Z",
     "start_time": "2023-12-26T14:20:47.781427Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ebe6d15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:21:04.436682Z",
     "start_time": "2023-12-26T14:21:00.549070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 意大利：罗马、威尼斯、佛罗伦萨等；\n",
      "\n",
      "2. 瑞士：日内瓦、卢塞恩；\n",
      "\n",
      "3. 加拿大：蒙特利尔；\n",
      "\n",
      "4. 法国：巴黎；\n",
      "\n",
      "5. 美国：纽约。\n"
     ]
    }
   ],
   "source": [
    "text = \"对于喜欢吃意大利面的人来说，有哪些 5 个度假胜地？\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7657e1e9",
   "metadata": {},
   "source": [
    "### Prompt Templates: Manage prompts for LLMs 提示模板：管理LLM的提示\n",
    "\n",
    "1. 从prompt模板中选择一个提示词模板\n",
    "2. 实例化一个提示词模板，设定参数，其中包括输入变量，可以将变量插入到模板中\n",
    "3. 格式化模板，将输入变量插入到模板中\n",
    "4. 用语言模型预测输入文本变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "168f2277",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:22:13.223070Z",
     "start_time": "2023-12-26T14:21:59.875252Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d6d3761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:23:46.720037Z",
     "start_time": "2023-12-26T14:23:46.713665Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"请提供5个度假胜地，为那些喜欢吃{food}的人。\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "160f8a0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:24:35.617073Z",
     "start_time": "2023-12-26T14:24:35.609479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请提供5个度假胜地，为那些喜欢吃西红柿的人。\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(food=\"西红柿\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4309f2a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:24:47.655434Z",
     "start_time": "2023-12-26T14:24:40.142162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 意大利西西里岛：拥有优质热带水果，其中包括新鲜西红柿和芒果。\n",
      "\n",
      "2. 墨西哥普埃布拉：令人惊奇的热带气温，让西红柿熟透，太阳照耀。\n",
      "\n",
      "3. 西班牙加那利群岛：位于大西洋的西班牙海岸，丰富的新鲜蔬菜和西红柿赢得大家的喜\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(food=\"西红柿\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd0c523",
   "metadata": {},
   "source": [
    "### Chains: Combine LLMs and prompts in multi-step workflows 链式：在多步骤工作流中结合LLMs和提示\n",
    "\n",
    "1. 从llms中选择一个语言模型、从prompt模板中选择一个提示词模板、从chains中选择一个链\n",
    "2. 实例化一个语言模型、一个带变量的提示词模板，并设定参数\n",
    "3. 实例化一个链，并设定语言模型和提示词作为相应参数\n",
    "3. 用链预测输入文本变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a34ff024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:26:23.582495Z",
     "start_time": "2023-12-26T14:24:56.786657Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffbdf4a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:26:40.309382Z",
     "start_time": "2023-12-26T14:26:40.212014Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"请提供5个度假胜地，为那些喜欢吃{food}的人。\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7efda77b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:26:40.437465Z",
     "start_time": "2023-12-26T14:26:40.432182Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b08b76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:26:44.698112Z",
     "start_time": "2023-12-26T14:26:41.062742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1.  南太平洋-斐济\n",
      "2.  圣托马斯-海南岛\n",
      "3.  冰岛\n",
      "4.  加勒比海-牙买加\n",
      "5.  墨西哥西南部-夏威夷\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"椰子\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850668f0",
   "metadata": {},
   "source": [
    "### Agents: Dynamically call chains based on user input 代理：根据用户输入动态调用链。\n",
    "1. 从llms中选择一个语言模型、从agents中选择初始化代理、从agents中选择加载工具\n",
    "2. 实例化一个语言模型、工具清单\n",
    "3. 实例化代理，并设定语言模型和工具作为相应参数\n",
    "4. 用代理预测输入文本变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19db4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-search-results\n",
    "\n",
    "!pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d22c464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:30:30.175655Z",
     "start_time": "2023-12-26T14:30:30.170134Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba25bb42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:30:30.721002Z",
     "start_time": "2023-12-26T14:30:30.633637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0740ce8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:35:18.657385Z",
     "start_time": "2023-12-26T14:35:18.462725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load in some tools to use 加载一些工具来使用\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"81957c5457c456d68fff27545dcbec279f54cf021c6b278d62050b0abf2477a3\"\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b20f48e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:35:52.998900Z",
     "start_time": "2023-12-26T14:35:52.990009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finally, let's initialize an agent with:最后，让我们用以下方式初始化一个代理：\n",
    "# 1. The tools 工具\n",
    "# 2. The language model 语言模型\n",
    "# 3. The type of agent we want to use. 我们想使用的代理类型。\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f2cf54",
   "metadata": {},
   "source": [
    "See list of agents types [here](https://python.langchain.com/docs/modules/agents/agent_types/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f9e6436830880fd8"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89728919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:38:58.016467Z",
     "start_time": "2023-12-26T14:38:49.878247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m I need to find out who the leader of Japan is and then use a calculator to find the largest prime number that is smaller than their age.\n",
      "Action: Search\n",
      "Action Input: \"Current leader of Japan\"\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mFumio Kishida is the current prime minister of Japan, replacing Yoshihide Suga on 4 October 2021. As of 22 December 2023, there have been 64 individual prime ministers serving 101 terms of office.\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I need to use a calculator to find the largest prime number that is smaller than the prime minister's age.\n",
      "Action: Calculator\n",
      "Action Input: 64\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3mAnswer: 64\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I now know the final answer.\n",
      "Final Answer: The largest prime number that is smaller than the age of the current leader of Japan is 64.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'The largest prime number that is smaller than the age of the current leader of Japan is 64.'"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test it out!\n",
    "agent.run(\"Who is the current leader of Japan? What is the largest prime number that is smaller than their age?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8808dc66",
   "metadata": {},
   "source": [
    "### Memory: Add state to chains and agents 内存：为链和代理添加状态\n",
    "\n",
    "1. 从llms中选择一个语言模型、并导入对话链\n",
    "2. 实例化一个语言模型、对话链\n",
    "3. 用对话链预测输入文本变量\n",
    "4. 对话链会记住上一次的输入文本变量作为对话历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc3294d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:39:19.196873Z",
     "start_time": "2023-12-26T14:39:19.187282Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "397ac43c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:39:37.494784Z",
     "start_time": "2023-12-26T14:39:37.399406Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9823cde5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:40:01.179965Z",
     "start_time": "2023-12-26T14:39:59.507738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" Hi there! It's nice to meet you. How can I help you today?\""
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3d547bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:41:11.228709Z",
     "start_time": "2023-12-26T14:41:08.767845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我做得很好！只是在和人工智能对话\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' 嗨！很高兴能和你对话！我可以为你提供什么帮助？'"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"我做得很好！只是在和人工智能对话\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb71a25c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:41:48.041471Z",
     "start_time": "2023-12-26T14:41:45.348368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我做得很好！只是在和人工智能对话\n",
      "AI:  嗨！很高兴能和你对话！我可以为你提供什么帮助？\n",
      "Human: 我对你说的第一句话是什么？\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' 你对我说的第一句话是“Hi there!”'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"我对你说的第一句话是什么？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d7daf49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T14:42:16.479525Z",
     "start_time": "2023-12-26T14:42:14.920394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我做得很好！只是在和人工智能对话\n",
      "AI:  嗨！很高兴能和你对话！我可以为你提供什么帮助？\n",
      "Human: 我对你说的第一句话是什么？\n",
      "AI:  你对我说的第一句话是“Hi there!”\n",
      "Human: what is an alternative phrase for the first thing I said to you?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' An alternative phrase for the first thing you said to me is \"Greetings!\"'"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is an alternative phrase for the first thing I said to you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3934501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
